{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install TensorRT and Cuda Using Pip"
      ],
      "metadata": {
        "id": "DSHpQPGWkUJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-pyindex\n",
        "!pip install --upgrade nvidia-tensorrt\n",
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnlvXgJCkS7x",
        "outputId": "88d9e7c0-e90d-4aa8-fb1e-35bcfdcd813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=47e9f7c8fd77e7738f55e84680c26b0949e8ddfd02dc68ec18cce864c493ce9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17283 sha256=3b8577508e37aed3abe02e27074c5718e7802cc65f145a739b9e106939b05a9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt, nvidia-tensorrt\n",
            "Successfully installed nvidia-tensorrt-99.0.0 tensorrt-8.6.1.post1\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.4)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661205 sha256=80cb3c4446ff5132f7ca97983ee84e014cb1f4641d60aac5bc5d5aa92ae8cf49\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.2 pycuda-2024.1 pytools-2023.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Python Modules"
      ],
      "metadata": {
        "id": "OHZ7OliZj5XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "from collections import OrderedDict,namedtuple\n",
        "\n",
        "# allows getting of files from google drive\n",
        "import gdown"
      ],
      "metadata": {
        "id": "xxio1MNjj4AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Files from Google Drive"
      ],
      "metadata": {
        "id": "x6gqBbUosp-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test sources zip file url\n",
        "test_zip_url = \"https://drive.google.com/file/d/1WOQLXYLGmXeSBlMRCkA56UM11m6--ETc/view?usp=sharing\"\n",
        "test_zip_output = \"Test Sources.zip\"\n",
        "\n",
        "gdown.download(test_zip_url, test_zip_output, quiet = False, fuzzy = True)\n",
        "\n",
        "# model file - v100\n",
        "gpu = \"v100\"\n",
        "\n",
        "if gpu == 't4':\n",
        "  model_url = \"https://drive.google.com/file/d/1-8qbCDQmtfOrErRvV274DG7ERnhyfyO9/view?usp=sharing\"\n",
        "  model_output = \"yolov7-self-driving-T4.trt\"\n",
        "elif gpu == \"v100\":\n",
        "  model_url = \"https://drive.google.com/file/d/1OizWs0pjEdCdTQj17-HpA0da7v9CMff0/view?usp=sharing\"\n",
        "  model_output = \"yolov7-self-driving-v100.trt\"\n",
        "else:\n",
        "  print(\"No A100 model yet\")\n",
        "\n",
        "gdown.download(model_url, model_output, quiet = False, fuzzy = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Twsjd7EvstYX",
        "outputId": "85e88998-2297-4f89-8fa6-b6b6a359cee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WOQLXYLGmXeSBlMRCkA56UM11m6--ETc\n",
            "From (redirected): https://drive.google.com/uc?id=1WOQLXYLGmXeSBlMRCkA56UM11m6--ETc&confirm=t&uuid=81f281df-3f52-40fa-abf3-7324de467193\n",
            "To: /content/Test Sources.zip\n",
            "100%|██████████| 2.24G/2.24G [00:21<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OizWs0pjEdCdTQj17-HpA0da7v9CMff0\n",
            "To: /content/yolov7-self-driving-v100.trt\n",
            "100%|██████████| 76.6M/76.6M [00:00<00:00, 109MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yolov7-self-driving-v100.trt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip uk and rare and difficult Tests Zip"
      ],
      "metadata": {
        "id": "N7McncURxlUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip \"/content/Test Sources.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO_zHl8gxu0I",
        "outputId": "af8fc97a-c892-40ae-cade-9474b43479a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Test Sources.zip\n",
            "   creating: Rare or Difficult Conditions Tests/\n",
            "   creating: Rare or Difficult Conditions Tests/First Party/\n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded 1.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded 2.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded 3.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded 4.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 1.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 2.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 3.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 4.mp4  \n",
            "   creating: Rare or Difficult Conditions Tests/Third Party/\n",
            "  inflating: Rare or Difficult Conditions Tests/Third Party/Test Rare or Difficult Conditions Third Party 3.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/Third Party/Test Rare or Difficult Conditions Third Party 4.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/Third Party/Test Rare or Difficult Conditions Third Party 5.mp4  \n",
            "  inflating: Rare or Difficult Conditions Tests/Third Party/Test Rare or Difficult Conditions Third Party 6.mp4  \n",
            "   creating: UK Road Tests/\n",
            "  inflating: UK Road Tests/UK Road Tests 1.mp4  \n",
            " extracting: UK Road Tests/UK Road Tests 10.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 2.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 3.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 4.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 5.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 6.mp4  \n",
            "  inflating: UK Road Tests/UK Road Tests 7.mp4  \n",
            " extracting: UK Road Tests/UK Road Tests 8.mp4  \n",
            " extracting: UK Road Tests/UK Road Tests 9.mp4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "t3t1v-LrmRbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change to relevant path\n",
        "PATH_TO_MODEL_WEIGHTS = \"/content/yolov7-self-driving-v100.trt\"\n",
        "\n",
        "GPU_DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "CLASS_NAMES = ['pedestrian', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'traffic light', 'traffic sign']\n",
        "\n",
        "CLASS_COLOURS = {\n",
        "    'pedestrian' : (199, 27, 185), # pink\n",
        "    'rider': (130, 140, 0), # dark green\n",
        "    'car' : (97, 248, 37), # lime green\n",
        "    'truck' : (255, 0, 0), # red\n",
        "    'bus' : (24, 226, 195), # turquoise\n",
        "    'train' : (255, 127, 117), # salmon\n",
        "    'motorcycle' : (227, 217, 30), # yellow\n",
        "    'bicycle' : (113, 10, 187), # purple\n",
        "    'traffic light' : (28, 45, 199), # blue\n",
        "    'traffic sign' : (255, 127, 0) # orange\n",
        "}"
      ],
      "metadata": {
        "id": "-0SYyWlumTI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deserialize TensorRT Engine (Fine-Tuned Model) and Set up Execution\n",
        "This code will prepare a TensorRT engine for predicting objects location and class by setting up the necessary data structures and execution context"
      ],
      "metadata": {
        "id": "BnoQLMDGlnzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init the tensor engine\n",
        "binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
        "logger = trt.Logger(trt.Logger.INFO)\n",
        "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
        "\n",
        "# get model from given path and deserialize it\n",
        "try:\n",
        "  with open(PATH_TO_MODEL_WEIGHTS, 'rb') as f, trt.Runtime(logger) as runtime:\n",
        "      model = runtime.deserialize_cuda_engine(f.read())\n",
        "except Exception as e:\n",
        "  print(f'Failed to deserialize the model: {e}')\n",
        "\n",
        "bindings = OrderedDict()\n",
        "for index in range(model.num_bindings):\n",
        "    name = model.get_tensor_name(index)\n",
        "    dtype = trt.nptype(model.get_tensor_dtype(name))\n",
        "    shape = tuple(model.get_tensor_shape(name))\n",
        "    data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(GPU_DEVICE)\n",
        "    bindings[name] = binding(name, dtype, shape, data, int(data.data_ptr()))\n",
        "\n",
        "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
        "\n",
        "# allows for the execution of the model on data\n",
        "context = model.create_execution_context()\n",
        "\n",
        "# warmup 10 times\n",
        "for i in range(10):\n",
        "  temp = torch.randn(1, 3, 640, 640)\n",
        "  binding_addrs['image'] = int(temp.data_ptr())\n",
        "  context.execute_v2(list(binding_addrs.values()))"
      ],
      "metadata": {
        "id": "Ad_WAPzkljmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code to Resize Input Image to 640*640"
      ],
      "metadata": {
        "id": "0IoHz1VilCrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img(img):\n",
        "  new_img_size = (640, 640)\n",
        "  padding_colour = (114, 114, 114)\n",
        "  current_img_size = img.shape[:2]\n",
        "\n",
        "  # calculate the minimum scale ratio to ge the image to the new size\n",
        "  scale_ratio = min(new_img_size[0] / current_img_size[0], new_img_size[1] / current_img_size[1])\n",
        "\n",
        "  # adding padding to maintain the current aspect ratio of the input image for post processing\n",
        "  new_unpadded = int(round(current_img_size[1] * scale_ratio)), int(round(current_img_size[0] * scale_ratio))\n",
        "  width_padding = new_img_size[1] - new_unpadded[0]\n",
        "  height_padding = new_img_size[0] - new_unpadded[1]\n",
        "\n",
        "  # divide the padding into 2 sides\n",
        "  width_padding /= 2\n",
        "  height_padding /=2\n",
        "\n",
        "  # if the size of the input image and desired size are not the same then resize\n",
        "  if current_img_size[::-1] != new_unpadded:\n",
        "    img = cv2.resize(img, new_unpadded, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # calculate the required padding for the image\n",
        "  top = int(round(height_padding - 0.1))\n",
        "  bottom = int(round(height_padding + 0.1))\n",
        "  left = int(round(width_padding - 0.1))\n",
        "  right = int(round(width_padding + 0.1))\n",
        "\n",
        "  # add padding to the image\n",
        "  img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_colour)\n",
        "  return img, scale_ratio, (width_padding, height_padding)"
      ],
      "metadata": {
        "id": "Kz5y5x8olXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postprocessing to Reverse Resizing of Input Image of the Image and Model Predictions"
      ],
      "metadata": {
        "id": "zBkbA_9c6GJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocessing(boxes, scale_ratio, width_height_padding):\n",
        "  width_height_padding = torch.tensor(width_height_padding * 2).to(boxes.device)\n",
        "  boxes -= width_height_padding\n",
        "  boxes /= scale_ratio\n",
        "  return boxes"
      ],
      "metadata": {
        "id": "18T6YEqM6U80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Run the Model on Inputted Image"
      ],
      "metadata": {
        "id": "94-2FCVH0qen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_image_through_model(input_image):\n",
        "  # run preprocessing on the image\n",
        "  img_pre = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "  image = img_pre.copy()\n",
        "\n",
        "  # resize img\n",
        "  image, scale_ratio, width_height_padding = resize_img(image)\n",
        "  image = image.transpose((2, 0, 1))\n",
        "  image = np.expand_dims(image, 0)\n",
        "  image = np.ascontiguousarray(image)\n",
        "\n",
        "  img = image.astype(np.float32)\n",
        "  img =  torch.from_numpy(img).to(GPU_DEVICE)\n",
        "\n",
        "  # normalise image\n",
        "  img /= 255\n",
        "\n",
        "  # run the image through the model\n",
        "  binding_addrs['images'] = int(img.data_ptr())\n",
        "  context.execute_v2(list(binding_addrs.values()))\n",
        "\n",
        "  # run postprocessing on the image\n",
        "  nums = bindings['num_dets'].data\n",
        "  boxes = bindings['det_boxes'].data\n",
        "  scores = bindings['det_scores'].data\n",
        "  classes = bindings['det_classes'].data\n",
        "  nums.shape,boxes.shape,scores.shape,classes.shape\n",
        "\n",
        "  boxes = boxes[0,:nums[0][0]]\n",
        "  scores = scores[0,:nums[0][0]]\n",
        "  classes = classes[0,:nums[0][0]]\n",
        "\n",
        "  for box,score,cl in zip(boxes,scores,classes):\n",
        "      box = postprocessing(box, scale_ratio, width_height_padding).round().int()\n",
        "      name = CLASS_NAMES[cl]\n",
        "      colour = CLASS_COLOURS[name]\n",
        "      name += ' ' + str(round(float(score),3))\n",
        "      cv2.rectangle(input_image, box[:2].tolist(), box[2:].tolist(), colour, 2)\n",
        "\n",
        "      # print text on top of box\n",
        "      (w, h), _ = cv2.getTextSize(name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
        "      cv2.rectangle(input_image, (box[0].tolist(), box[1].tolist() - 20), (box[0].tolist() + w, box[1].tolist()), colour, -1)\n",
        "      cv2.putText(input_image, name, (int(box[0]), int(box[1]) - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), thickness=1)\n",
        "\n",
        "  # return predicted frame\n",
        "  return input_image"
      ],
      "metadata": {
        "id": "tahS9EDB0wIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Process a Video File and run through the model"
      ],
      "metadata": {
        "id": "bSWVdyX85qYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_file(video_path, output_video_path_and_name):\n",
        "  video_in = cv2.VideoCapture(video_path)\n",
        "\n",
        "  # get the first frame from the video\n",
        "  success, frame = video_in.read()\n",
        "\n",
        "  # create output video\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "  width = frame.shape[1]\n",
        "  height = frame.shape[0]\n",
        "  fps = video_in.get(cv2.CAP_PROP_FPS)\n",
        "  video_out = cv2.VideoWriter(output_video_path_and_name + '.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "  frame_count = 0\n",
        "  while success:\n",
        "    # run frame through model\n",
        "    predicted_frame = run_image_through_model(frame)\n",
        "\n",
        "    # add frame to output video\n",
        "    video_out.write(frame)\n",
        "\n",
        "    # read next frame\n",
        "    success, frame = video_in.read()\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "  print(f\"{frame_count} Frames Processed for Inputted Video\")\n",
        "\n",
        "  # input video processed, release output video\n",
        "  video_out.release()"
      ],
      "metadata": {
        "id": "nZwwvXny4Xdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_video_file(\"/content/UK Road Tests/UK Road Tests 9.mp4\", \"/content/test/test\")"
      ],
      "metadata": {
        "id": "Efzsv3tlBp0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Performance Tests"
      ],
      "metadata": {
        "id": "oKkxqtFu2WkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create results folder structure\n",
        "! mkdir results\n",
        "! mkdir \"results/UK Road Test Output\"\n",
        "\n",
        "! mkdir \"results/Rare or Difficult Conditions Tests Output\"\n",
        "! mkdir \"results/Rare or Difficult Conditions Tests Output/First Party\"\n",
        "! mkdir \"results/Rare or Difficult Conditions Tests Output/Third Party\""
      ],
      "metadata": {
        "id": "xXyBxey2-Fv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WY8eZY-F9bZ",
        "outputId": "767cb0d4-d53a-4a81-8a60-8cbee0b0b706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Videos...\n",
            "Processing File UK Road Tests 1.mp4\n",
            "Estimated Seconds to Complete 25.382835\n",
            "UK Road Tests 1\n",
            "300 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 3.mp4\n",
            "Estimated Seconds to Complete 123.98115247776875\n",
            "UK Road Tests 3\n",
            "2100 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 10.mp4\n",
            "Estimated Seconds to Complete 29.58211643340668\n",
            "UK Road Tests 10\n",
            "600 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 8.mp4\n",
            "Estimated Seconds to Complete 21.117152340513844\n",
            "UK Road Tests 8\n",
            "450 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 5.mp4\n",
            "Estimated Seconds to Complete 13.828854562927601\n",
            "UK Road Tests 5\n",
            "300 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 7.mp4\n",
            "Estimated Seconds to Complete 25.152506787251625\n",
            "UK Road Tests 7\n",
            "600 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 6.mp4\n",
            "Estimated Seconds to Complete 19.217330875679192\n",
            "UK Road Tests 6\n",
            "480 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 2.mp4\n",
            "Estimated Seconds to Complete 11.108123186987655\n",
            "UK Road Tests 2\n",
            "300 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 9.mp4\n",
            "Estimated Seconds to Complete 183.47713995791116\n",
            "UK Road Tests 9\n",
            "4500 Frames Processed for Inputted Video\n",
            "Processing File UK Road Tests 4.mp4\n",
            "Estimated Seconds to Complete 76.93432380111776\n",
            "UK Road Tests 4\n",
            "1800 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Third Party 4.mp4\n",
            "Estimated Seconds to Complete 13.549853295514273\n",
            "Test Rare or Difficult Conditions Third Party 4\n",
            "328 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Third Party 3.mp4\n",
            "Estimated Seconds to Complete 3.289429630620018\n",
            "Test Rare or Difficult Conditions Third Party 3\n",
            "563 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Third Party 6.mp4\n",
            "Estimated Seconds to Complete 62.39093070991248\n",
            "Test Rare or Difficult Conditions Third Party 6\n",
            "2281 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Third Party 5.mp4\n",
            "Estimated Seconds to Complete 25.299955467153154\n",
            "Test Rare or Difficult Conditions Third Party 5\n",
            "702 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded Overexposed 1.mp4\n",
            "Estimated Seconds to Complete 199.97100517514048\n",
            "Test Rare or Difficult Conditions Self Recorded Overexposed 1\n",
            "2100 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded Overexposed 3.mp4\n",
            "Estimated Seconds to Complete 75.99487852483594\n",
            "Test Rare or Difficult Conditions Self Recorded Overexposed 3\n",
            "1350 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded 3.mp4\n",
            "Estimated Seconds to Complete 57.689693420546284\n",
            "Test Rare or Difficult Conditions Self Recorded 3\n",
            "1350 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded 4.mp4\n",
            "Estimated Seconds to Complete 74.51704460948294\n",
            "Test Rare or Difficult Conditions Self Recorded 4\n",
            "1800 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded 1.mp4\n",
            "Estimated Seconds to Complete 75.51919912961635\n",
            "Test Rare or Difficult Conditions Self Recorded 1\n",
            "2100 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded Overexposed 2.mp4\n",
            "Estimated Seconds to Complete 66.88555093696918\n",
            "Test Rare or Difficult Conditions Self Recorded Overexposed 2\n",
            "1770 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded Overexposed 4.mp4\n",
            "Estimated Seconds to Complete 70.55843383831589\n",
            "Test Rare or Difficult Conditions Self Recorded Overexposed 4\n",
            "1800 Frames Processed for Inputted Video\n",
            "Processing File Test Rare or Difficult Conditions Self Recorded 2.mp4\n",
            "Estimated Seconds to Complete 62.21407254442608\n",
            "Test Rare or Difficult Conditions Self Recorded 2\n",
            "1770 Frames Processed for Inputted Video\n",
            "Finished Processing Videos...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "print(\"Processing Videos...\")\n",
        "\n",
        "uk_road_tests_folder = \"/content/UK Road Tests\"\n",
        "rare_or_difficult_conditions_video_folder = \"/content/Rare or Difficult Conditions Tests\"\n",
        "\n",
        "average_mb_per_second = 1\n",
        "\n",
        "# process uk_road_tests_folder\n",
        "# get video files in folder\n",
        "uk_test_videos = os.listdir(uk_road_tests_folder)\n",
        "\n",
        "for video in uk_test_videos:\n",
        "  file_size_mb = os.path.getsize(uk_road_tests_folder + \"/\" + video) / 1000000\n",
        "  file_name = video.split('.')[0]\n",
        "\n",
        "  print(f'Processing File {video}')\n",
        "  print(f'Estimated Seconds to Complete {(file_size_mb / average_mb_per_second)}')\n",
        "\n",
        "  start_time = time.time()\n",
        "  process_video_file(uk_road_tests_folder + \"/\" + video, file_name)\n",
        "  end_time = time.time()\n",
        "\n",
        "  mb_per_second = file_size_mb / (end_time - start_time)\n",
        "\n",
        "  average_mb_per_second += mb_per_second\n",
        "  average_mb_per_second /= 2\n",
        "\n",
        "# process rare or difficult conditions\n",
        "rare_or_difficult_videos = os.listdir(rare_or_difficult_conditions_video_folder)\n",
        "\n",
        "for party_type in rare_or_difficult_videos:\n",
        "  video_files = os.listdir(rare_or_difficult_conditions_video_folder + \"/\" + party_type)\n",
        "\n",
        "  for video in video_files:\n",
        "    file_size_mb = os.path.getsize(rare_or_difficult_conditions_video_folder + \"/\" + party_type + \"/\" + video) / 1000000\n",
        "    file_name = video.split(('.'))[0]\n",
        "\n",
        "    print(f'Processing File {video}')\n",
        "    print(f'Estimated Seconds to Complete {(file_size_mb / average_mb_per_second)}')\n",
        "\n",
        "    start_time = time.time()\n",
        "    process_video_file(rare_or_difficult_conditions_video_folder + \"/\" + party_type + \"/\" + video, file_name)\n",
        "    end_time = time.time()\n",
        "\n",
        "    mb_per_second = file_size_mb / (end_time - start_time)\n",
        "\n",
        "    average_mb_per_second += mb_per_second\n",
        "    average_mb_per_second /= 2\n",
        "\n",
        "print(\"Finished Processing Videos...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip Results Folder"
      ],
      "metadata": {
        "id": "FwbAsrUL19Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r \"/content/results.zip\" \"/content/results\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQe-m-dX2A7B",
        "outputId": "f03ba0e0-37cf-4100-aae2-d100b1524d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/ (stored 0%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/Third Party/ (stored 0%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/Third Party/Test Rare or Difficult Conditions Third Party 4.mp4 (deflated 4%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/Third Party/Test Rare or Difficult Conditions Third Party 3.mp4 (deflated 8%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/Third Party/Test Rare or Difficult Conditions Third Party 6.mp4 (deflated 4%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/Third Party/Test Rare or Difficult Conditions Third Party 5.mp4 (deflated 2%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/ (stored 0%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 1.mp4 (deflated 2%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 3.mp4 (deflated 5%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded 3.mp4 (deflated 11%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded 4.mp4 (deflated 19%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded 1.mp4 (deflated 4%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 2.mp4 (deflated 3%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded Overexposed 4.mp4 (deflated 10%)\n",
            "  adding: content/results/Rare or Difficult Conditions Tests Output/First Party/Test Rare or Difficult Conditions Self Recorded 2.mp4 (deflated 6%)\n",
            "  adding: content/results/UK Road Test Output/ (stored 0%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 1.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 3.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 10.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 8.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 5.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 7.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 6.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 2.mp4 (deflated 1%)\n",
            "  adding: content/results/UK Road Test Output/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 9.mp4 (deflated 2%)\n",
            "  adding: content/results/UK Road Test Output/UK Road Tests 4.mp4 (deflated 1%)\n"
          ]
        }
      ]
    }
  ]
}